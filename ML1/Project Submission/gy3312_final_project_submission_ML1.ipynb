{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSC5825\n",
    "#Fall2020\n",
    "#Name: Jaydeb Sarker\n",
    "#ID: gy3312\n",
    "#credit card fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import classifiers and others\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.utils import resample \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import collections\n",
    "\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data=pd.read_csv('creditcard.csv')\n",
    "    return data\n",
    "\n",
    "data=read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data[\"Class\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data without fraud:  99.827\n",
      "The data with fraud:      0.173\n"
     ]
    }
   ],
   "source": [
    "print('The data without fraud: ',round(data[\"Class\"].value_counts()[0]/len(data)*100,3))\n",
    "print('The data with fraud:     ',round(data[\"Class\"].value_counts()[1]/len(data)*100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Class', 'PCATime',\n",
       "       'PCA amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##apply preprocessing\n",
    "columns= data[['Time', 'Amount']]\n",
    "pca = PCA()\n",
    "pca.fit(columns)\n",
    "X_PCA = pca.transform(columns)\n",
    "\n",
    "data['PCATime']=X_PCA[:,0]\n",
    "data['PCA amount']=X_PCA[:,1]\n",
    "\n",
    "data.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (7:3) split for supervised learning\n",
    "X_train, X_test= train_test_split(data, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199364, 31)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    85288\n",
      "1      155\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_test['Class'].value_counts())\n",
    "\n",
    "#test data without upsampling\n",
    "X_test_t= X_test.drop([\"Class\"], axis=1)\n",
    "Y_test= X_test[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199027, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    199027\n",
       "0    199027\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply upsampling to the trained data\n",
    "maj_class=X_train[X_train[\"Class\"]==0]\n",
    "min_class=X_train[X_train[\"Class\"]==1]\n",
    "\n",
    "\n",
    "resamp_minclass=resample(min_class,n_samples=199027,replace=True,random_state=42)\n",
    "print(resamp_minclass.shape)\n",
    "\n",
    "Xtrain_new= pd.concat([maj_class,resamp_minclass])\n",
    "Xtrain_new[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398054, 30)\n"
     ]
    }
   ],
   "source": [
    "upsampling_X= Xtrain_new.drop([\"Class\"], axis=1)\n",
    "upsampling_y= Xtrain_new[\"Class\"]\n",
    "\n",
    "print(upsampling_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##apply supervised models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "upsampling_pipe = []\n",
    "\n",
    "upsampling_pipe.append(('upsamp_LR', Pipeline([('samp_LR',LogisticRegression(max_iter=1000))])))\n",
    "\n",
    "upsampling_pipe.append(('upsamp_DCT', Pipeline([('DCT',DecisionTreeClassifier())])))\n",
    "\n",
    "upsampling_pipe.append(('upsamp_NB', Pipeline([('NB',GaussianNB())])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upsamp_LR: 0.930981 (0.034118)\n",
      "upsamp_DCT: 0.999794 (0.000229)\n",
      "upsamp_NB: 0.862879 (0.127681)\n"
     ]
    }
   ],
   "source": [
    "#10 fold cross validation after upsampling\n",
    "\n",
    "upsamp_results = []\n",
    "names = []\n",
    "for name, model in upsampling_pipe:\n",
    "    kfold = KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "    ups_cv_results = cross_val_score(model, upsampling_X, upsampling_y, cv=kfold)\n",
    "    upsamp_results.append(ups_cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, ups_cv_results.mean(), ups_cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/tfgpu-3.6.8/lib/python3.6/site-packages/ipykernel_launcher.py:10: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"papertype\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/anaconda/envs/tfgpu-3.6.8/lib/python3.6/site-packages/ipykernel_launcher.py:10: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"frameon\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Algorithm comparison\n",
    "fig = plt.figure(figsize=(5,3.5))\n",
    "fig.suptitle('Model Comparison during training')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(upsamp_results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.savefig(\"comparison.png\" , dpi=None, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None, metadata=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of LR is:  0.9451377268972528\n",
      "0.9740411736479291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     85288\n",
      "           1       0.06      0.92      0.11       155\n",
      "\n",
      "    accuracy                           0.97     85443\n",
      "   macro avg       0.53      0.95      0.55     85443\n",
      "weighted avg       1.00      0.97      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##apply logistic regression to the train data\n",
    "\n",
    "LR=LogisticRegression(max_iter=1000)\n",
    "                \n",
    "kF= KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "LR.fit(upsampling_X, upsampling_y)\n",
    "LR_predictions=LR.predict(X_test_t)\n",
    "\n",
    "score=roc_auc_score(Y_test, LR_predictions)\n",
    "print(\"Accuracy Score of LR is: \", score)\n",
    "\n",
    "LR_predictions\n",
    "print(accuracy_score(Y_test,LR_predictions))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, LR_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy Score of DT is:  0.8804223866913168\n",
      "0.9991222218320986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85288\n",
      "           1       0.76      0.76      0.76       155\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.88      0.88      0.88     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##Apply Decision Tree for train and test\n",
    "DT=DecisionTreeClassifier()\n",
    "                \n",
    "kF= KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "DT.fit(upsampling_X, upsampling_y)\n",
    "DT_predictions=DT.predict(X_test_t)\n",
    "\n",
    "score=roc_auc_score(Y_test, DT_predictions)\n",
    "print(\" Accuracy Score of DT is: \", score)\n",
    "\n",
    " \n",
    "print(accuracy_score(Y_test, DT_predictions))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, DT_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of NB is:  0.8922952516104826\n",
      "0.9906838477113398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     85288\n",
      "           1       0.14      0.79      0.24       155\n",
      "\n",
      "    accuracy                           0.99     85443\n",
      "   macro avg       0.57      0.89      0.62     85443\n",
      "weighted avg       1.00      0.99      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##apply Naive Bayes to the train data and test it\n",
    "\n",
    "NB=GaussianNB() \n",
    "                \n",
    "kF= KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "NB.fit(upsampling_X, upsampling_y)\n",
    "NB_predictions=NB.predict(X_test_t)\n",
    "\n",
    "score=roc_auc_score(Y_test, NB_predictions)\n",
    "print(\"Accuracy Score of NB is: \", score)\n",
    "\n",
    " \n",
    "print(accuracy_score(Y_test, NB_predictions))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, NB_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nValid transactions as our population\\nFraud transactions as sample\\nTwo tailed Z-test\\nLevel of significance 0.01\\nCorresponding critical value is 2.58\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Apply Unsupervised Learning Method Isolation Forest\n",
    "\n",
    "#Feature Selection using Z-test\n",
    "''' \n",
    "Valid transactions as our population\n",
    "Fraud transactions as sample\n",
    "Two tailed Z-test\n",
    "Level of significance 0.01\n",
    "Corresponding critical value is 2.58\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ztest(feature):\n",
    "    \n",
    "    mean = normal[feature].mean()\n",
    "    std = fraud[feature].std()\n",
    "    zScore = (fraud[feature].mean() - mean) / (std/np.sqrt(sample_size))\n",
    "    \n",
    "    return zScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1  is statistically significant\n",
      "V2  is statistically significant\n",
      "V3  is statistically significant\n",
      "V4  is statistically significant\n",
      "V5  is statistically significant\n",
      "V6  is statistically significant\n",
      "V7  is statistically significant\n",
      "V9  is statistically significant\n",
      "V10  is statistically significant\n",
      "V11  is statistically significant\n",
      "V12  is statistically significant\n",
      "V14  is statistically significant\n",
      "V16  is statistically significant\n",
      "V17  is statistically significant\n",
      "V18  is statistically significant\n",
      "V19  is statistically significant\n",
      "V20  is statistically significant\n",
      "V21  is statistically significant\n",
      "V24  is statistically significant\n",
      "V27  is statistically significant\n",
      "V28  is statistically significant\n",
      "PCATime  is statistically significant\n",
      "PCA amount  is statistically significant\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns= data.drop('Class', axis=1).columns\n",
    "normal= data[data.Class==0]\n",
    "fraud= data[data.Class==1]\n",
    "sample_size=len(fraud)\n",
    "significant_features=[]\n",
    "cvalue=2.58 # it is ideal value\n",
    "\n",
    "\n",
    "for i in columns:\n",
    "    \n",
    "    z_value=ztest(i)\n",
    "    \n",
    "    if( abs(z_value) >= cvalue):    \n",
    "        print(i,\" is statistically significant\") #Reject Null hypothesis. i.e. H0\n",
    "        significant_features.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 24)\n"
     ]
    }
   ],
   "source": [
    "significant_features.append('Class')\n",
    "data= data[significant_features]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017304750013189597\n",
      "Fraud Cases: 492\n",
      "Valid Transactions: 284315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##verify fraud and non-fraud\n",
    "Fraud = data[data['Class'] == 1]\n",
    "Valid = data[data['Class'] == 0]\n",
    "\n",
    "outlier_fraction = len(Fraud)/float(len(Valid))\n",
    "print(outlier_fraction)\n",
    "\n",
    "print('Fraud Cases: {}'.format(len(data[data['Class'] == 1])))\n",
    "print('Valid Transactions: {}'.format(len(data[data['Class'] == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 23)\n",
      "(284807,)\n"
     ]
    }
   ],
   "source": [
    "columns = data.columns.tolist()\n",
    "\n",
    "# Filter the columns to remove data we do not want\n",
    "columns = [c for c in columns if c not in [\"Class\"]]\n",
    "\n",
    "# Store the variable we'll be predicting on\n",
    "target = \"Class\"\n",
    "\n",
    "X = data[columns]\n",
    "Y = data[target]\n",
    "\n",
    "# Print shapes\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/tfgpu-3.6.8/lib/python3.6/site-packages/sklearn/ensemble/_iforest.py:255: FutureWarning: 'behaviour' is deprecated in 0.22 and will be removed in 0.24. You should not pass or set this parameter.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :\n",
      "0.9978336206624135\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    284315\n",
      "           1       0.37      0.37      0.37       492\n",
      "\n",
      "    accuracy                           1.00    284807\n",
      "   macro avg       0.69      0.69      0.69    284807\n",
      "weighted avg       1.00      1.00      1.00    284807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Applying Isolation Forest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "state= 42\n",
    "IF = IsolationForest(n_estimators = 1050, max_features = 1.0, max_samples=1.0, \n",
    "                        behaviour=\"new\", bootstrap=False, random_state=22,\n",
    "                        contamination = outlier_fraction)\n",
    "#ISF = IsolationForest(random_state=state)\n",
    "IF.fit(X)\n",
    "\n",
    "scores_prediction = IF.decision_function(X)\n",
    "y_pred = IF.predict(X)\n",
    "\n",
    "\n",
    "#Reshape the prediction values \n",
    "y_pred[y_pred == 1] = 0\n",
    "y_pred[y_pred == -1] = 1\n",
    "n_errors = (y_pred != Y).sum()\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "print(\"Accuracy Score :\")\n",
    "print(accuracy_score(Y,y_pred))\n",
    "print(\"Classification Report :\")\n",
    "print(classification_report(Y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
