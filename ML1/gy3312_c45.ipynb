{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gy3312\n",
    "#jaydebsarker\n",
    "#hw5:DT\n",
    "\n",
    "import csv \n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCSV(file):\n",
    "    \"\"\"Loads a CSV file and converts all floats and ints into basic datatypes.\"\"\" \n",
    "    def convertTypes(s):\n",
    "        s = s.strip()\n",
    "        try:\n",
    "            return float(s) if '.' in s else int(s)\n",
    "        except ValueError:\n",
    "            return s\n",
    "\n",
    "    reader = csv.reader(open(file, 'rt'))\n",
    "    return [[convertTypes(item) for item in row] for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "trainingData = loadCSV('adult.csv')\n",
    "\n",
    "print(trainingData[0])\n",
    "\n",
    "df = pd.DataFrame(trainingData)\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df['income_num'] = pd.factorize(df['income'])[0]\n",
    "\n",
    "df = df.drop(['income'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['income_num'], axis=1), df['income_num'], test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating DT classes\n",
    "#I created the DT from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \"\"\"Decision tree implementation using c4.5 algorithm\"\"\"\n",
    "    def __init__(self, col=-1, value=None, trueBranch=None, falseBranch=None, results=None):\n",
    "        self.col = col\n",
    "        self.value = value\n",
    "        self.trueBranch = trueBranch\n",
    "        self.falseBranch = falseBranch\n",
    "        self.results = results # None for nodes, not None for leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideSet(rows, column, value):\n",
    "    splittingFunction = None\n",
    "    if isinstance(value, int) or isinstance(value, float): # for int and float values\n",
    "        splittingFunction = lambda row : row[column] >= value\n",
    "    else: # for strings \n",
    "        splittingFunction = lambda row : row[column] == value\n",
    "    list1 = [row for row in rows if splittingFunction(row)]\n",
    "    list2 = [row for row in rows if not splittingFunction(row)]\n",
    "    return (list1, list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueCounts(rows):\n",
    "    results = {}\n",
    "    for row in rows:\n",
    "        r = row[-1]\n",
    "        if r not in results: results[r] = 0\n",
    "        results[r] += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(rows):\n",
    "    from math import log\n",
    "    log2 = lambda x: log(x)/log(2)\n",
    "    results = uniqueCounts(rows)\n",
    "\n",
    "    entr = 0.0\n",
    "    for r in results:\n",
    "        p = float(results[r])/len(rows)\n",
    "        entr -= p*log2(p)\n",
    "    return entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(rows):\n",
    "    total = len(rows)\n",
    "    counts = uniqueCounts(rows)\n",
    "    imp = 0.0\n",
    "\n",
    "    for k1 in counts:\n",
    "        p1 = float(counts[k1])/total  \n",
    "        for k2 in counts:\n",
    "            if k1 == k2: continue\n",
    "            p2 = float(counts[k2])/total\n",
    "            imp += p1*p2\n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(rows):\n",
    "    if len(rows) == 0: return 0\n",
    "    data = [float(row[len(row) - 1]) for row in rows]\n",
    "    mean = sum(data) / len(data)\n",
    "\n",
    "    variance = sum([(d-mean)**2 for d in data]) / len(data)\n",
    "    return variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def growDecisionTreeFrom(rows, evaluationFunction=entropy):\n",
    "  \n",
    "\n",
    "    if len(rows) == 0: return DecisionTree()\n",
    "    currentScore = evaluationFunction(rows)\n",
    "\n",
    "    bestGain = 0.0\n",
    "    bestAttribute = None\n",
    "    bestSets = None\n",
    "\n",
    "    columnCount = len(rows[0]) - 1  # last column is the result/target column\n",
    "    for col in range(0, columnCount):\n",
    "        columnValues = [row[col] for row in rows]\n",
    "\n",
    "        for value in columnValues:\n",
    "            (set1, set2) = divideSet(rows, col, value)\n",
    "\n",
    "            # Gain -- Entropy or Gini\n",
    "            p = float(len(set1)) / len(rows)\n",
    "            gain = currentScore - p*evaluationFunction(set1) - (1-p)*evaluationFunction(set2)\n",
    "            if gain>bestGain and len(set1)>0 and len(set2)>0:\n",
    "                bestGain = gain\n",
    "                bestAttribute = (col, value)\n",
    "                bestSets = (set1, set2)\n",
    "\n",
    "    if bestGain > 0:\n",
    "        trueBranch = growDecisionTreeFrom(bestSets[0])\n",
    "        falseBranch = growDecisionTreeFrom(bestSets[1])\n",
    "        return DecisionTree(col=bestAttribute[0], value=bestAttribute[1], trueBranch=trueBranch, falseBranch=falseBranch)\n",
    "    else:\n",
    "        return DecisionTree(results=uniqueCounts(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-15-3b52805771da>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-3b52805771da>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    tree.trueBranch, tree.falseBranch = None, None\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def prune(tree, minGain, evaluationFunction=entropy, notify=False):\n",
    "    \n",
    "    # recursive call for each branch\n",
    "    if tree.trueBranch.results == None: prune(tree.trueBranch, minGain, evaluationFunction, notify)\n",
    "    if tree.falseBranch.results == None: prune(tree.falseBranch, minGain, evaluationFunction, notify)\n",
    "\n",
    "    # merge leaves (potentionally)\n",
    "    if tree.trueBranch.results != None and tree.falseBranch.results != None:\n",
    "        tb, fb = [], []\n",
    "\n",
    "        for v, c in tree.trueBranch.results.items(): tb += [[v]] * c\n",
    "        for v, c in tree.falseBranch.results.items(): fb += [[v]] * c\n",
    "\n",
    "        p = float(len(tb)) / len(tb + fb)\n",
    "        delta = evaluationFunction(tb+fb) - p*evaluationFunction(tb) - (1-p)*evaluationFunction(fb)\n",
    "        if delta < minGain:\t\n",
    "            if notify:  \n",
    "            tree.trueBranch, tree.falseBranch = None, None\n",
    "            tree.results = uniqueCounts(tb + fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(observations, tree, dataMissing=False):\n",
    " \n",
    "\n",
    "    def classifyWithoutMissingData(observations, tree):\n",
    "        if tree.results != None:  # leaf\n",
    "            return tree.results\n",
    "        else:\n",
    "            v = observations[tree.col]\n",
    "            branch = None\n",
    "            if isinstance(v, int) or isinstance(v, float):\n",
    "                if v >= tree.value: branch = tree.trueBranch\n",
    "                else: branch = tree.falseBranch\n",
    "            else:\n",
    "                if v == tree.value: branch = tree.trueBranch\n",
    "                else: branch = tree.falseBranch\n",
    "        return classifyWithoutMissingData(observations, branch)\n",
    "\n",
    "\n",
    "    def classifyWithMissingData(observations, tree):\n",
    "        if tree.results != None:  # leaf \n",
    "            return tree.results\n",
    "        else:\n",
    "            v = observations[tree.col]\n",
    "            if v == None:\n",
    "                tr = classifyWithMissingData(observations, tree.trueBranch)\n",
    "                fr = classifyWithMissingData(observations, tree.falseBranch)\n",
    "                tcount = sum(tr.values())\n",
    "                fcount = sum(fr.values())\n",
    "                tw = float(tcount)/(tcount + fcount)\n",
    "                fw = float(fcount)/(tcount + fcount)\n",
    "                result = collections.defaultdict(int)\n",
    "                for k, v in tr.items(): result[k] += v*tw\n",
    "                for k, v in fr.items(): result[k] += v*fw\n",
    "                return dict(result)\n",
    "            else:\n",
    "                branch = None\n",
    "                if isinstance(v, int) or isinstance(v, float):\n",
    "                    if v >= tree.value: branch = tree.trueBranch\n",
    "                    else: branch = tree.falseBranch\n",
    "                else:\n",
    "                    if v == tree.value: branch = tree.trueBranch\n",
    "                    else: branch = tree.falseBranch\n",
    "            return classifyWithMissingData(observations, branch)\n",
    "\n",
    "    # function body\n",
    "    if dataMissing: \n",
    "        return classifyWithMissingData(observations, tree)\n",
    "    else: \n",
    "        return classifyWithoutMissingData(observations, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(decisionTree):\n",
    "    \"\"\"Plots the obtained decision tree. \"\"\"\n",
    "    def toString(decisionTree, indent=''):\n",
    "        if decisionTree.results != None:  # leaf node\n",
    "            return str(decisionTree.results)\n",
    "        else:\n",
    "            if isinstance(decisionTree.value, int) or isinstance(decisionTree.value, float):\n",
    "                decision = 'Column %s: x >= %s?' % (decisionTree.col, decisionTree.value)\n",
    "            else:\n",
    "                decision = 'Column %s: x == %s?' % (decisionTree.col, decisionTree.value)\n",
    "            trueBranch = indent + 'yes -> ' + toString(decisionTree.trueBranch, indent + '\\t\\t')\n",
    "            falseBranch = indent + 'no  -> ' + toString(decisionTree.falseBranch, indent + '\\t\\t')\n",
    "            return (decision + '\\n' + trueBranch + '\\n' + falseBranch)\n",
    "\n",
    "    print(toString(decisionTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'capital.gain', 'capital.loss', 'hours.per.week', 'native.country', 'income']\n"
     ]
    }
   ],
   "source": [
    "#run classifier\n",
    "\n",
    " \n",
    "X_tr = X_train\n",
    "X_tr['income_num'] = y_train #add the target value\n",
    "\n",
    "p = X_tr.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree = growDecisionTreeFrom(p)\n",
    "#decisionTree = growDecisionTreeFrom(trainingData, evaluationFunction=gini) # with gini\n",
    "#plot(decisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A branch was pruned: gain = 0.032600\n",
      "A branch was pruned: gain = 0.116115\n",
      "A branch was pruned: gain = 0.007914\n",
      "A branch was pruned: gain = 0.070012\n",
      "A branch was pruned: gain = 0.080136\n",
      "Error for cut-off:  0.2  is: 0.20690978886756237\n",
      "A branch was pruned: gain = 0.391244\n",
      "A branch was pruned: gain = 0.258019\n",
      "A branch was pruned: gain = 0.297472\n",
      "A branch was pruned: gain = 0.371232\n",
      "A branch was pruned: gain = 0.337290\n",
      "A branch was pruned: gain = 0.391244\n",
      "A branch was pruned: gain = 0.337290\n",
      "A branch was pruned: gain = 0.371232\n",
      "A branch was pruned: gain = 0.371232\n",
      "A branch was pruned: gain = 0.276195\n",
      "A branch was pruned: gain = 0.337290\n",
      "A branch was pruned: gain = 0.205110\n",
      "A branch was pruned: gain = 0.228538\n",
      "A branch was pruned: gain = 0.322757\n",
      "A branch was pruned: gain = 0.322757\n",
      "A branch was pruned: gain = 0.391244\n",
      "A branch was pruned: gain = 0.020714\n",
      "A branch was pruned: gain = 0.337290\n",
      "A branch was pruned: gain = 0.391244\n",
      "A branch was pruned: gain = 0.276195\n",
      "A branch was pruned: gain = 0.175856\n",
      "A branch was pruned: gain = 0.249882\n",
      "A branch was pruned: gain = 0.162292\n",
      "Error for cut-off:  0.4  is: 0.21401151631477927\n",
      "A branch was pruned: gain = 0.468996\n",
      "A branch was pruned: gain = 0.257679\n",
      "A branch was pruned: gain = 0.097478\n",
      "A branch was pruned: gain = 0.138241\n",
      "A branch was pruned: gain = 0.054901\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.068075\n",
      "A branch was pruned: gain = 0.413817\n",
      "A branch was pruned: gain = 0.468996\n",
      "A branch was pruned: gain = 0.257679\n",
      "A branch was pruned: gain = 0.311690\n",
      "A branch was pruned: gain = 0.543564\n",
      "A branch was pruned: gain = 0.550341\n",
      "A branch was pruned: gain = 0.143157\n",
      "A branch was pruned: gain = 0.120943\n",
      "A branch was pruned: gain = 0.308890\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.293564\n",
      "A branch was pruned: gain = 0.109170\n",
      "A branch was pruned: gain = 0.543564\n",
      "A branch was pruned: gain = 0.281036\n",
      "A branch was pruned: gain = 0.439497\n",
      "A branch was pruned: gain = 0.517802\n",
      "A branch was pruned: gain = 0.160112\n",
      "A branch was pruned: gain = 0.293564\n",
      "A branch was pruned: gain = 0.084350\n",
      "A branch was pruned: gain = 0.061347\n",
      "A branch was pruned: gain = 0.468996\n",
      "A branch was pruned: gain = 0.413817\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.293564\n",
      "A branch was pruned: gain = 0.543564\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.503258\n",
      "A branch was pruned: gain = 0.468996\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.293564\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.079448\n",
      "A branch was pruned: gain = 0.192209\n",
      "A branch was pruned: gain = 0.543564\n",
      "A branch was pruned: gain = 0.281036\n",
      "A branch was pruned: gain = 0.193507\n",
      "A branch was pruned: gain = 0.101434\n",
      "A branch was pruned: gain = 0.139439\n",
      "A branch was pruned: gain = 0.543564\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.293564\n",
      "A branch was pruned: gain = 0.439497\n",
      "A branch was pruned: gain = 0.247150\n",
      "A branch was pruned: gain = 0.179329\n",
      "A branch was pruned: gain = 0.242859\n",
      "A branch was pruned: gain = 0.413817\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.293564\n",
      "A branch was pruned: gain = 0.140781\n",
      "A branch was pruned: gain = 0.543564\n",
      "A branch was pruned: gain = 0.550341\n",
      "A branch was pruned: gain = 0.303307\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.027796\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.044184\n",
      "A branch was pruned: gain = 0.413817\n",
      "A branch was pruned: gain = 0.237397\n",
      "A branch was pruned: gain = 0.439497\n",
      "A branch was pruned: gain = 0.439497\n",
      "A branch was pruned: gain = 0.503258\n",
      "A branch was pruned: gain = 0.060785\n",
      "A branch was pruned: gain = 0.150856\n",
      "A branch was pruned: gain = 0.543564\n",
      "A branch was pruned: gain = 0.543564\n",
      "A branch was pruned: gain = 0.543564\n",
      "A branch was pruned: gain = 0.503258\n",
      "A branch was pruned: gain = 0.503258\n",
      "A branch was pruned: gain = 0.037040\n",
      "A branch was pruned: gain = 0.413817\n",
      "A branch was pruned: gain = 0.045316\n",
      "A branch was pruned: gain = 0.013562\n",
      "A branch was pruned: gain = 0.439497\n",
      "A branch was pruned: gain = 0.407468\n",
      "A branch was pruned: gain = 0.242859\n",
      "A branch was pruned: gain = 0.591673\n",
      "A branch was pruned: gain = 0.293564\n",
      "A branch was pruned: gain = 0.321928\n",
      "A branch was pruned: gain = 0.143607\n",
      "A branch was pruned: gain = 0.543564\n",
      "A branch was pruned: gain = 0.038984\n",
      "Error for cut-off:  0.6  is: 0.21900191938579655\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.067852\n",
      "A branch was pruned: gain = 0.109298\n",
      "A branch was pruned: gain = 0.015047\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.316689\n",
      "A branch was pruned: gain = 0.122556\n",
      "A branch was pruned: gain = 0.197160\n",
      "A branch was pruned: gain = 0.170951\n",
      "A branch was pruned: gain = 0.111348\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.072627\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.469565\n",
      "A branch was pruned: gain = 0.218388\n",
      "A branch was pruned: gain = 0.143391\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.316689\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.112717\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.466917\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.090475\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.305958\n",
      "A branch was pruned: gain = 0.395816\n",
      "A branch was pruned: gain = 0.305159\n",
      "A branch was pruned: gain = 0.166009\n",
      "A branch was pruned: gain = 0.218219\n",
      "A branch was pruned: gain = 0.352298\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.466917\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.099481\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.305958\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.109008\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.548795\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.113579\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.469565\n",
      "A branch was pruned: gain = 0.224788\n",
      "A branch was pruned: gain = 0.108032\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.466917\n",
      "A branch was pruned: gain = 0.218995\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.684038\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.305958\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.094848\n",
      "A branch was pruned: gain = 0.150856\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.316689\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.316689\n",
      "A branch was pruned: gain = 0.191346\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.316689\n",
      "A branch was pruned: gain = 0.378879\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.102690\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.316689\n",
      "A branch was pruned: gain = 0.183150\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.033396\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.316689\n",
      "A branch was pruned: gain = 0.185968\n",
      "A branch was pruned: gain = 0.198969\n",
      "A branch was pruned: gain = 0.139947\n",
      "A branch was pruned: gain = 0.136145\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.548795\n",
      "A branch was pruned: gain = 0.316538\n",
      "A branch was pruned: gain = 0.195473\n",
      "A branch was pruned: gain = 0.282688\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.469565\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.316689\n",
      "A branch was pruned: gain = 0.152007\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.316689\n",
      "A branch was pruned: gain = 0.191346\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.469565\n",
      "A branch was pruned: gain = 0.224788\n",
      "A branch was pruned: gain = 0.204362\n",
      "A branch was pruned: gain = 0.199191\n",
      "A branch was pruned: gain = 0.109170\n",
      "A branch was pruned: gain = 0.144484\n",
      "A branch was pruned: gain = 0.154331\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.278072\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.305958\n",
      "A branch was pruned: gain = 0.721928\n",
      "A branch was pruned: gain = 0.358931\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.093532\n",
      "A branch was pruned: gain = 0.033662\n",
      "A branch was pruned: gain = 0.013604\n",
      "A branch was pruned: gain = 0.003589\n",
      "A branch was pruned: gain = 0.012451\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.349978\n",
      "A branch was pruned: gain = 0.251629\n",
      "A branch was pruned: gain = 0.650022\n",
      "A branch was pruned: gain = 0.305958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for cut-off:  0.8  is: 0.28291746641074855\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "cutof = [0.2,0.4,0.6,0.8]\n",
    "for i in cutof:\n",
    "    prune(decisionTree, i, notify=True)\n",
    "    #cou = 0\n",
    "    err = 0\n",
    "    for ind in range(X_val.shape[0]):\n",
    "         \n",
    "        m = False\n",
    "        for j in range(X_val.shape[1]):\n",
    "            v = str(X_val._get_value(ind, j, takeable = True))\n",
    "            if v=='?':\n",
    "                #print(X_val.iloc[ind])\n",
    "                m = True\n",
    "                break\n",
    "\n",
    "        inst = X_val.iloc[ind].values.flatten().tolist()\n",
    "        #print(inst)\n",
    "        #print(classify(['37', 'private','188774', 'Bachelors', '13', 'Never-married','Exec-managerial','Not-in-family', 'White', 'Male', '0', '2824','40','United-States'], decisionTree, dataMissing=False))\n",
    "        s = str(classify(inst, decisionTree, dataMissing=m))\n",
    "        if s[1]!=str(y_val.iloc[ind]):\n",
    "            err+=1\n",
    "            #print(s[1]) \n",
    "        #cou +=1\n",
    "\n",
    "    print(\"Error for cut-off: \",i,\" is:\",err/X_val.shape[0])\n",
    "    error.append(err/X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWdElEQVR4nO3df5Bd533X8fcnkpWouMEpXkosqbJDFRM1OFZ7Iwit6yYVWO6A7FBIZBDUjMHTNKIDbhycMdNhXAZaLQWmE89glcnQdoaotifxqNSKUhSlCRCBV8iRK3mUkUUSSW6jTaloM1L9K1/+uGfdq9VZaXels/dK+37N7Og8z3nO3e8zd3c/Oj/uOakqJEma7g3DLkCSNJoMCElSKwNCktTKgJAktTIgJEmtlg67gMvl+uuvrxtvvHHYZUjSFWX//v3frKqxtnVXTUDceOONTExMDLsMSbqiJPnaTOs8xCRJamVASJJaGRCSpFYGhCSplQEhSWp11VzFJEmLzVMHTjK++wgvnj7LDdct58E7bubudSsu2+sbEJJ0BXrqwEk+9qnnOPvKawCcPH2Wj33qOYDLFhIeYpKkK9D47iOvh8OUs6+8xvjuI5ftexgQknQFevH02Tn1z4cBIUlXoBuuWz6n/vkwICTpCvTgHTez/Jol5/Qtv2YJD95x82X7Hp6klqQr0NSJaK9ikiSd5+51Ky5rIEzX6SGmJBuTHElyNMlDLesfSHI4ycEke5KsHli3LcmhJM8n+aUk6bJWSdK5OguIJEuAR4E7gbXAPUnWTht2AOhV1S3Ak8C2Ztu/AvwgcAvwTuDdwO1d1SpJOl+XexDrgaNVdayqXgZ2AHcNDqiqvVV1pmnuA1ZOrQLeBCwD3ghcA3yjw1olSdN0GRArgOMD7RNN30zuA3YBVNWXgL3A7zZfu6vq+ekbJLk/yUSSicnJyctWuCRpRC5zTbIF6AHjTft7gXfQ36NYAbwvyW3Tt6uq7VXVq6re2FjrE/MkSfPUZUCcBFYNtFc2fedIsgF4GNhUVS813e8H9lXVt6rqW/T3LN7TYa2SpGm6DIhngDVJbkqyDNgM7BwckGQd8Bj9cDg1sOrrwO1Jlia5hv4J6vMOMUmSutNZQFTVq8BWYDf9P+6PV9WhJI8k2dQMGweuBZ5I8mySqQB5EngBeA74MvDlqvqNrmqVJJ0vVTXsGi6LXq9XExMTwy5Dkq4oSfZXVa9t3UicpJYkjR4DQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLUyICRJrQwISVKrTgMiycYkR5IcTfJQy/oHkhxOcjDJniSrm/73No8gnfr64yR3d1mrJOlcnQVEkiXAo8CdwFrgniRrpw07APSq6hb6z6HeBlBVe6vq1qq6FXgfcAb4bFe1SpLO1+UexHrgaFUdq6qXgR3AXYMDmiA40zT3AStbXudvAbsGxkmSFkCXAbECOD7QPtH0zeQ+YFdL/2bgk20bJLk/yUSSicnJyXkXKkk630icpE6yBegB49P63wr8RWB323ZVtb2qelXVGxsb675QSVpElnb42ieBVQPtlU3fOZJsAB4Gbq+ql6at/gDw6ap6pbMqJUmtutyDeAZYk+SmJMvoHyraOTggyTrgMWBTVZ1qeY17mOHwkiSpW50FRFW9Cmylf3joeeDxqjqU5JEkm5ph48C1wBPN5ayvB0iSG+nvgfx2VzVKkmbW5SEmqupp4OlpfT87sLzhAtt+lQuf1JYkdWgkTlJLkkaPASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSpVacBkWRjkiNJjiZ5qGX9A0kOJzmYZE+S1QPrvifJZ5M834y5sctaJUnn6iwgkiwBHgXuBNYC9yRZO23YAaBXVbcATwLbBtb9KjBeVe8A1gOnuqpVknS+Lvcg1gNHq+pYVb0M7ADuGhxQVXur6kzT3AesBGiCZGlV/VYz7lsD4yRJC6DLgFgBHB9on2j6ZnIfsKtZfjtwOsmnkhxIMt7skZwjyf1JJpJMTE5OXrbCJUkjcpI6yRagB4w3XUuB24CPAO8G3gbcO327qtpeVb2q6o2NjS1QtZK0OHQZECeBVQPtlU3fOZJsAB4GNlXVS033CeDZ5vDUq8BTwPd3WKskaZouA+IZYE2Sm5IsAzYDOwcHJFkHPEY/HE5N2/a6JFO7Be8DDndYqyRpms4Covmf/1ZgN/A88HhVHUrySJJNzbBx4FrgiSTPJtnZbPsa/cNLe5I8BwT45a5qlSSdL1U17Boui16vVxMTE8MuQ5KuKEn2V1Wvbd1InKSWJI0eA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSq04DIsnGJEeSHE3yUMv6B5IcTnIwyZ4kqwfWvdY8hvT1R5FKkhbO0q5eOMkS4FHgrwIngGeS7KyqwwPDDgC9qjqT5EPANuCDzbqzVXVrV/VJki6syz2I9cDRqjpWVS8DO4C7BgdU1d6qOtM09wErO6xHkjQHXQbECuD4QPtE0zeT+4BdA+03JZlIsi/J3W0bJLm/GTMxOTl5yQVLkv5EZ4eY5iLJFqAH3D7QvbqqTiZ5G/C5JM9V1QuD21XVdmA7QK/XqwUrWJIWgS73IE4CqwbaK5u+cyTZADwMbKqql6b6q+pk8+8x4PPAug5rlSRN02VAPAOsSXJTkmXAZuCcq5GSrAMeox8Opwb635Lkjc3y9cAPAoMntyVJHevsEFNVvZpkK7AbWAJ8oqoOJXkEmKiqncA4cC3wRBKAr1fVJuAdwGNJvk0/xH5+2tVPkqSOperqOHTf6/VqYmJi2GVI0hUlyf6q6rWt85PUkqRWBoQkqZUBIUlqZUBIklpdNCCSvCHJBxaiGEnS6LhoQFTVt4GPLkAtkqQRMttDTP81yUeSrEryXVNfnVYmSRqq2X5QbuoW3B8e6CvgbZe3HEnSqJhVQFTVTV0XIkkaLRc8xJTkowPLf3vaun/VVVGSpOG72DmIzQPLH5u2buNlrkWSNEIuFhCZYbmtLUm6ilwsIGqG5ba2JOkqcrGT1O9K8of09xaWN8s07Td1WpkkaaguGBBVtWShCpEkjRbvxSRJamVASJJadRoQSTYmOZLkaJKHWtY/kORwkoNJ9iRZPW39m5OcSPLxLuuUJJ2vs4BIsgR4FLgTWAvck2TttGEHgF5V3QI8CWybtv7ngC90VaMkaWZd7kGsB45W1bGqehnYAdw1OKCq9lbVmaa5D1g5tS7JDwDfDXy2wxolSTPoMiBWAMcH2ieavpncB+yC/jMogF8EPnKhb5Dk/iQTSSYmJycvsVxJ0qCROEmdZAvQA8abrp8Cnq6qExfarqq2V1WvqnpjY2NdlylJi8psb/c9HyeBVQPtlU3fOZJsAB4Gbq+ql5ru9wC3Jfkp4FpgWZJvVdV5J7olSd3oMiCeAdYkuYl+MGwG/s7ggCTrgMeAjVV1aqq/qv7uwJh76Z/INhwkaQF1doipql4FtgK7geeBx6vqUJJHkmxqho3T30N4IsmzSXZ2VY8kaW5SdXXcc6/X69XExMSwy5CkK0qS/VXVa1s3EiepJUmjx4CQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1KrTgEiyMcmRJEeTnPdM6SQPJDmc5GCSPUlWN/2rk/zv5jGkh5L8ZJd1SpLO11lAJFkCPArcCawF7kmydtqwA0Cvqm4BngS2Nf2/C7ynqm4F/hLwUJIbuqpVknS+Lvcg1gNHq+pYVb0M7ADuGhxQVXur6kzT3AesbPpfrqqXmv43dlynJKlFl394VwDHB9onmr6Z3AfsmmokWZXkYPMav1BVL07fIMn9SSaSTExOTl6msiVJMCL/M0+yBegB41N9VXW8OfT0vcBPJPnu6dtV1faq6lVVb2xsbOEKlqRFoMuAOAmsGmivbPrOkWQD8DCwaeCw0uuaPYffAW7rqE5JUosuA+IZYE2Sm5IsAzYDOwcHJFkHPEY/HE4N9K9MsrxZfgvwQ8CRDmuVJE2ztKsXrqpXk2wFdgNLgE9U1aEkjwATVbWT/iGla4EnkgB8vao2Ae8AfjFJAQH+TVU911WtkqTzpaqGXcNl0ev1amJiYthlSNIVJcn+quq1rRuJk9SSpNFjQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlq1WlAJNmY5EiSo0kealn/QJLDSQ4m2ZNkddN/a5IvJTnUrPtgl3VKks7XWUAkWQI8CtwJrAXuSbJ22rADQK+qbgGeBLY1/WeAv19V3wdsBP59kuu6qlWSdL6lHb72euBoVR0DSLIDuAs4PDWgqvYOjN8HbGn6vzIw5sUkp4Ax4HSH9Uq6gKcOnGR89xFePH2WG65bzoN33Mzd61YMuyx1qMtDTCuA4wPtE03fTO4Ddk3vTLIeWAa80LLu/iQTSSYmJycvsVxJM3nqwEk+9qnnOHn6LAWcPH2Wj33qOZ46cHLYpalDI3GSOskWoAeMT+t/K/BrwD+oqm9P366qtldVr6p6Y2NjC1OstAiN7z7C2VdeO6fv7CuvMb77yJAq0kLo8hDTSWDVQHtl03eOJBuAh4Hbq+qlgf43A78JPFxV+zqsU9JFvHj67Jz6dXXocg/iGWBNkpuSLAM2AzsHByRZBzwGbKqqUwP9y4BPA79aVU92WKOkWbjhuuVz6tfVobOAqKpXga3AbuB54PGqOpTkkSSbmmHjwLXAE0meTTIVIB8Afhi4t+l/NsmtXdUq6cIevONmll+z5Jy+5dcs4cE7bh5SRVoIqaph13BZ9Hq9mpiYGHYZ0lXLq5iuTkn2V1WvbV2X5yAkXUXuXrfCQFhkRuIqJknS6DEgJEmtDAhJUisDQpLUyoCQJLXyKiaNHC+nlEaDAaGRMnVTuKn7/kzdFA4wJKQF5iEmjRRvCieNDgNCI8Wbwkmjw4DQSPGmcNLoMCA0UrwpnDQ6PEmtkTJ1ItqrmKThMyA0crwpnDQaPMQkSWplQEiSWhkQkqRWnQZEko1JjiQ5muShlvUPJDmc5GCSPUlWD6z7TJLTSf5LlzVKktp1FhBJlgCPAncCa4F7kqydNuwA0KuqW4AngW0D68aBv9dVfZKkC+tyD2I9cLSqjlXVy8AO4K7BAVW1t6rONM19wMqBdXuAP+qwPknSBXQZECuA4wPtE03fTO4Dds3lGyS5P8lEkonJycl5lChJmslInKROsgXo0T+sNGtVtb2qelXVGxsb66Y4SVqkuvyg3Elg1UB7ZdN3jiQbgIeB26vqpQ7rkSTNQZd7EM8Aa5LclGQZsBnYOTggyTrgMWBTVZ3qsBZJ0hx1FhBV9SqwFdgNPA88XlWHkjySZFMzbBy4FngiybNJXg+QJF8EngB+NMmJJHd0Vask6Xyd3oupqp4Gnp7W97MDyxsusO1tHZb2Oh9vKUntFvXN+ny8pSTNbCSuYhoWH28pSTNb1AHh4y0laWaLOiB8vKUkzWxRB4SPt5SkmS3qk9Q+3lKSZraoAwJ8vKUkzWRRH2KSJM3MgJAktTIgJEmtDAhJUisDQpLUKlU17BouiySTwNcu4SWuB755mcoZpqtlHuBcRtXVMperZR5waXNZXVWtT1y7agLiUiWZqKresOu4VFfLPMC5jKqrZS5Xyzygu7l4iEmS1MqAkCS1MiD+xPZhF3CZXC3zAOcyqq6WuVwt84CO5uI5CElSK/cgJEmtDAhJUqtFFRBJNiY5kuRokoda1j+Q5HCSg0n2JFk9jDpnYxZz+ckkzyV5Nsl/S7J2GHXOxsXmMjDux5NUkpG9NHEW78u9SSab9+XZJP9wGHVezGzekyQfaH5fDiX5zwtd42zN4j35dwPvx1eSnB5CmbMyi7l8T5K9SQ40f8d+7JK+YVUtii9gCfAC8DZgGfBlYO20Me8FvqNZ/hDw68Ou+xLm8uaB5U3AZ4Zd93zn0oz7TuALwD6gN+y6L+F9uRf4+LBrvQzzWAMcAN7StP/ssOu+lJ+vgfH/GPjEsOu+hPdlO/ChZnkt8NVL+Z6LaQ9iPXC0qo5V1cvADuCuwQFVtbeqzjTNfcDKBa5xtmYzlz8caP4pYFSvRrjoXBo/B/wC8McLWdwczXYuo2428/hHwKNV9QcAVXVqgWucrbm+J/cAn1yQyuZuNnMp4M3N8p8GXryUb7iYAmIFcHygfaLpm8l9wK5OK5q/Wc0lyYeTvABsA356gWqbq4vOJcn3A6uq6jcXsrB5mO3P2I83u/9PJlm1MKXNyWzm8Xbg7Un+e5J9STYuWHVzM+vf++aQ8k3A5xagrvmYzVz+BbAlyQngafp7RPO2mAJi1pJsAXrA+LBruRRV9WhV/XngnwH/fNj1zEeSNwD/FviZYddymfwGcGNV3QL8FvArQ65nvpbSP8z0I/T/1/3LSa4bZkGXwWbgyap6bdiFXIJ7gP9UVSuBHwN+rfkdmpfFFBAngcH/ra1s+s6RZAPwMLCpql5aoNrmalZzGbADuLvLgi7BxebyncA7gc8n+Srwl4GdI3qi+qLvS1X9/sDP1X8EfmCBapuL2fx8nQB2VtUrVfV/gK/QD4xRM5fflc2M7uElmN1c7gMeB6iqLwFvon8jv/kZ9omXBTzBsxQ4Rn8XcuoEz/dNG7OO/kmgNcOu9zLMZc3A8t8AJoZd93znMm385xndk9SzeV/eOrD8fmDfsOue5zw2Ar/SLF9P/9DHnxl27fP9+QL+AvBVmg8Pj+LXLN+XXcC9zfI76J+DmPecls4lTK5kVfVqkq3AbvpXA3yiqg4leYT+H8+d9A8pXQs8kQTg61W1aWhFz2CWc9na7A29AvwB8BPDq3hms5zLFWGWc/npJJuAV4H/S/+qppEyy3nsBv5aksPAa8CDVfX7w6u63Rx+vjYDO6r5yzqKZjmXn6F/uO+f0j9hfe+lzMlbbUiSWi2mcxCSpDkwICRJrQwISVIrA0KS1MqAkCS1MiCkC0jy55LsSPJCkv1Jnk7y9ots80+SfMc8vtd4c2fU8SRjSf5nc1fO2+Y/A2n+vMxVmkH6H4b5H/Q/EPYfmr530b9T7hcvsN1X6X+Y75tz/H7/D/iuqnotyWZgQ1WN5O3AtTgsmg/KSfPwXuCVqXAAqKovAyT5EeAjVfXXm/bHgQn6d9K8Adib5JtV9d7BF2xCZxtwJ/0PMv3Lqvr1JDvpf0hzf5JPAh8Glje3FHlPVZ3tdKZSCwNCmtk7gf1z2aCqfinJA8B7Z9iD+JvArcC76N+i4pkkX6iqTUm+VVW3AiT5Bv29kK2XMgHpUngOQlpYPwR8sqpeq6pvAL8NvHvINUmtDAhpZoeY+W6rr3Lu78+b2gYlef/A4yxH8Q600owMCGlmnwPemOT+qY4ktzRXFX0NWJvkjc1zEH50YLs/on+bcqrq01V1a/M1AXwR+GCSJUnGgB8G/tcCzUeaEwNCmkFzF8z3Axuay1wPAf8a+L2qOk7/vvu/0/x7YGDT7cBnkuxtedlPAwfp36r5c8BHq+r3OpyGNG9e5ipJauUehCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIklr9f24e2jXakG3pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the error with cutoff for validation\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#print(error)\n",
    "#print(cutof)\n",
    "error1 = []\n",
    "for i in range(4):\n",
    "    error1.append(error[i])\n",
    "plt.scatter(cutof,error1)\n",
    "plt.xlabel(\"Cut-off \")\n",
    "plt.ylabel(\"Er\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error is: 0.27391371103945955\n"
     ]
    }
   ],
   "source": [
    "#testing data\n",
    "err = 0\n",
    "for ind in range(X_test.shape[0]):\n",
    "    \n",
    "    m = False\n",
    "    for j in range(X_test.shape[1]):\n",
    "        v = str(X_test._get_value(ind, j, takeable = True))\n",
    "        if v=='?':\n",
    "            #print(X_val.iloc[ind])\n",
    "            m = True\n",
    "            break\n",
    "\n",
    "    inst = X_test.iloc[ind].values.flatten().tolist()\n",
    "     \n",
    "    s = str(classify(inst, decisionTree, dataMissing=m))\n",
    "    if s[1]!=str(y_test.iloc[ind]):\n",
    "        err+=1\n",
    "    \n",
    "\n",
    "print(\"Test error is:\",err/X_test.shape[0])\n",
    "error.append(err/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([1,2,3,4,5],error,color=['blue','blue','blue','blue','red'])\n",
    "plt.xlabel(\"Instances (blue=validation data, red=test data)\")\n",
    "plt.ylabel(\"Err\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
