{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jaydeb sarker\n",
    "#gy3312\n",
    "\n",
    "##import packages\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "#import from sklearn\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import random as sparse_random\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder,scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    train_data = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    test_data = pd.read_csv(\"fashion-mnist_test.csv\")\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= get_train_data()\n",
    "test=  get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_features = train.iloc[:,1:23]\n",
    "XTrain_features = train.iloc[:,1:785]\n",
    "YTrain_features= train.iloc[:,0]\n",
    "\n",
    "#taking test data\n",
    "Xtest_features=test.iloc[:,1:785]\n",
    "Ytest_features = test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_Val, y_train, y_val = train_test_split(XTrain_features, YTrain_features, test_size=0.10, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the input train\n",
    "scaler = StandardScaler()\n",
    "XTrain_features = scaler.fit_transform(X_train)\n",
    "X_val=StandardScaler().fit_transform(X_Val.values)\n",
    "\n",
    "X_test = StandardScaler().fit_transform(Xtest_features.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#use PCA to reduce the features\n",
    "pca = PCA(n_components=10)\n",
    "\n",
    "train_pca= pca.fit(XTrain_features).transform(XTrain_features)\n",
    "val_pca=pca.fit(X_val).transform(X_val)\n",
    "\n",
    "test_pca = pca.fit(X_test).transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class K_Means:\n",
    "    def __init__(self, k, tol=0.001, max_iter=300):\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self, data):\n",
    "\n",
    "        self.centroids = {}\n",
    "        #random centroid initialization\n",
    "        for i in range(self.k):\n",
    "            r = np.random.randint(0, 50)\n",
    "            self.centroids[i] = data[r]\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.classifications = {}\n",
    "\n",
    "            for i in range(self.k):\n",
    "                self.classifications[i] = []\n",
    "\n",
    "            for featureset in data:\n",
    "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                classification = distances.index(min(distances))\n",
    "                self.classifications[classification].append(featureset)\n",
    "\n",
    "            prev_centroids = dict(self.centroids)\n",
    "\n",
    "            for classification in self.classifications:\n",
    "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "\n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
    "                    #print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "\n",
    "    def predict(self, data):\n",
    "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
    "        classification = distances.index(min(distances))\n",
    "        return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnumber_of_clusters = 10\\nkmeans = K_Means(number_of_clusters)\\n\\n\\nkmeans.fit(train_pca)\\nkmeans.predict(test_pca)\\n\\ncolors = 10*[\"green\",\"red\",\"gold\",\"blue\",\"silver\", \"yellow\", \"brown\", \"violet\", \"purple\"]\\n\\nfor centroid in kmeans.centroids:\\n    plt.scatter(kmeans.centroids[centroid][0], kmeans.centroids[centroid][1],\\n                marker=\"o\", color=\"k\", s=150, linewidths=5)\\n\\nfor classification in kmeans.classifications:\\n    color = colors[classification]\\n    for featureset in kmeans.classifications[classification]:\\n        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)\\n\\nplt.show()\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "number_of_clusters = 10\n",
    "kmeans = K_Means(number_of_clusters)\n",
    "\n",
    "\n",
    "kmeans.fit(train_pca)\n",
    "kmeans.predict(test_pca)\n",
    "\n",
    "colors = 10*[\"green\",\"red\",\"gold\",\"blue\",\"silver\", \"yellow\", \"brown\", \"violet\", \"purple\"]\n",
    "\n",
    "for centroid in kmeans.centroids:\n",
    "    plt.scatter(kmeans.centroids[centroid][0], kmeans.centroids[centroid][1],\n",
    "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
    "\n",
    "for classification in kmeans.classifications:\n",
    "    color = colors[classification]\n",
    "    for featureset in kmeans.classifications[classification]:\n",
    "        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)\n",
    "\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import math\n",
    "from scipy.special import comb\n",
    "def rand_index(labels_true, labels_pred):\n",
    "    \"\"\"given the true and predicted labels, \n",
    "    it will return the Rand Index.\n",
    "    Args:\n",
    "        labels_true: the real class labels \n",
    "        labels_pred:the predicted class labels\n",
    "    Return:\n",
    "        RAND_index\n",
    "    \"\"\"\n",
    "    # create list of all combinations with the length of labels.\n",
    "    my_pair = list(combinations(range(len(labels_true)), 2))\n",
    "\n",
    "    def is_equal(x):\n",
    "        return (x[0] == x[1])\n",
    "    \n",
    "    my_a = 0\n",
    "    my_b = 0\n",
    "    \n",
    "    for i in range(len(my_pair)):\n",
    "        if(is_equal((labels_true[my_pair[i][0]], labels_true[my_pair[i][1]])) == is_equal((labels_pred[my_pair[i][0]], labels_pred[my_pair[i][1]]))\n",
    "           and is_equal((labels_pred[my_pair[i][0]], labels_pred[my_pair[i][1]])) == True):\n",
    "            my_a += 1\n",
    "        if(is_equal((labels_true[my_pair[i][0]], labels_true[my_pair[i][1]])) == is_equal((labels_pred[my_pair[i][0]], labels_pred[my_pair[i][1]]))\n",
    "           and is_equal((labels_pred[my_pair[i][0]], labels_pred[my_pair[i][1]])) == False):\n",
    "            my_b += 1\n",
    "            \n",
    "    #my_denom = math.comb(len(labels_true), 2)\n",
    "    my_denom = comb(len(labels_true), 2)\n",
    "    RAND_index = (my_a + my_b) / my_denom\n",
    "    return RAND_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val=y_val.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K value#  5\n",
      "\n",
      "Rand score is:  0.5486427182308162\n",
      "\n",
      "Adj rand score is:  0.05860319850683295\n",
      "\n",
      "K value#  6\n",
      "\n",
      "Rand score is:  0.8244069011501917\n",
      "\n",
      "Adj rand score is:  0.2562503335035596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K value#  7\n",
      "\n",
      "Rand score is:  0.797223648385842\n",
      "\n",
      "Adj rand score is:  0.21836345751366176\n",
      "\n",
      "K value#  8\n",
      "\n",
      "Rand score is:  0.8417599599933322\n",
      "\n",
      "Adj rand score is:  0.26829803801905694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K value#  9\n",
      "\n",
      "Rand score is:  0.8401339112074234\n",
      "\n",
      "Adj rand score is:  0.27344772412866275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K value#  10\n",
      "\n",
      "Rand score is:  0.8401339112074234\n",
      "\n",
      "Adj rand score is:  0.27344772412866275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K value#  11\n",
      "\n",
      "Rand score is:  0.8609312107573485\n",
      "\n",
      "Adj rand score is:  0.2956514737807226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K value#  12\n",
      "\n",
      "Rand score is:  0.862961215758182\n",
      "\n",
      "Adj rand score is:  0.28426004805130595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K value#  13\n",
      "\n",
      "Rand score is:  0.8697107851308551\n",
      "\n",
      "Adj rand score is:  0.3006251311317496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K value#  14\n",
      "\n",
      "Rand score is:  0.8712973273323331\n",
      "\n",
      "Adj rand score is:  0.3014149539819299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K value#  15\n",
      "\n",
      "Rand score is:  0.8706984497416236\n",
      "\n",
      "Adj rand score is:  0.29962341144825916\n",
      "Best K is 14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "import numpy\n",
    "bestK=0\n",
    "rand_adj=0\n",
    "for k in range(5,16):\n",
    "    number_of_clusters = k\n",
    "    kmeans = K_Means(k)\n",
    "    \n",
    "    y_pred=[]\n",
    "    \n",
    "    kmeans.fit(train_pca)\n",
    "    \n",
    "    for valp in val_pca:\n",
    "        a=kmeans.predict(valp)\n",
    "        y_pred.append(a)\n",
    "    \n",
    "    \n",
    "    #y_pred=numpy.array(y_pred)\n",
    "    rand_score=rand_index(y_val,y_pred)\n",
    "    print(\"\\nK value# \", k)\n",
    "    print('\\nRand score is: ',rand_score)\n",
    "    #anindex=rand_score(y_val, y_pred)\n",
    "    \n",
    "    #rint('RandIndex',ranindex)\n",
    "    \n",
    "    scorerand=adjusted_rand_score(y_val, y_pred)\n",
    "    print('\\nAdj rand score is: ',scorerand)\n",
    "    if(rand_adj<rand_score):\n",
    "        rand_adj=rand_score\n",
    "        bestK=k\n",
    "    \n",
    "print('Best K is', bestK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run#  0\n",
      "\n",
      "Rand score is:  0.8874687868786879\n",
      "Adj rand score is:  0.35979836971189566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run#  1\n",
      "\n",
      "Rand score is:  0.8791159515951595\n",
      "Adj rand score is:  0.3310724225796255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run#  2\n",
      "\n",
      "Rand score is:  0.883726892689269\n",
      "Adj rand score is:  0.3464295977018881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run#  3\n",
      "\n",
      "Rand score is:  0.8843138313831383\n",
      "Adj rand score is:  0.3526989700235944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run#  4\n",
      "\n",
      "Rand score is:  0.8788998699869986\n",
      "Adj rand score is:  0.34984779280915973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/lib/function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/anaconda/envs/toxicity_detector/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run#  5\n",
      "\n",
      "Rand score is:  0.8872842084208421\n",
      "Adj rand score is:  0.34459174361953115\n"
     ]
    }
   ],
   "source": [
    "#converting to list \n",
    "Ytest_features=Ytest_features.values.tolist()\n",
    "for i in range(0,6):\n",
    "    kmeans = K_Means(bestK)\n",
    "    kmeans.fit(train_pca)\n",
    "    y_pred=[]\n",
    "    \n",
    "    #kmeans.fit(train_pca)\n",
    "    \n",
    "    for valt in test_pca:\n",
    "        a=kmeans.predict(valt)\n",
    "        y_pred.append(a)\n",
    "    \n",
    "    rand_score=rand_index(Ytest_features,y_pred)\n",
    "    print('\\nRun# ', i)\n",
    "    print('\\nRand score is: ',rand_score)\n",
    "    #anindex=rand_score(y_val, y_pred)\n",
    "    \n",
    "    #rint('RandIndex',ranindex)\n",
    "    \n",
    "    scorerand=adjusted_rand_score(Ytest_features, y_pred)\n",
    "    print('Adj rand score is: ',scorerand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
